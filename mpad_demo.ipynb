{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b230833",
   "metadata": {},
   "source": [
    "# 1. Overview\n",
    "\n",
    "This is a Demo project for the Matrix Profiling Anomaly Detection (MPAD) Framework.\n",
    "\n",
    "In this Demo project, we present the flow of the framework of using Matrix Profile (MP) approach for detecting the anomalies in time series data. The Matrix Profile measures the similarity joint between one time series with itself or two time series. The data in this similarity joint (i.e., the MP) could be leveraged to identify the similarities and differences, which is used in anomaly detection tasks in this Demo project.\n",
    "\n",
    "The MPAD Framework includes **5 steps** as shown in the framework below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a5db18",
   "metadata": {},
   "source": [
    "*(Left side of the figure shows the steps and the flow, and Right side of the figure shows the functions and variables developed in this demo project.)*\n",
    "<img src=\"imgs/flow_functions.png\" width=\"1200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e73d7c",
   "metadata": {},
   "source": [
    "\n",
    "### Step 1 - Data Extraction for the units of analysis\n",
    "\n",
    "The ***raw time series list*** benchmark_ts and evaluate_ts, and the MilePost (MP) int value are inputs of the Function `dataset_extraction()`, and be used to generate the list of desired ***segments from the time series***, including seg_benchmark_mp,seg_evaluate_mp, and their normalized arrays: seg_benchmark_mp_scaled,seg_evaluate_mp_scaled.\n",
    "\n",
    "- Function `ts_normalize()` is called in `dataset_extraction()` to take in a time series dataframe ts and transform it into the mean-normlaized version\n",
    "\n",
    "\n",
    "### Step 2 - Generate matrix profile\n",
    "\n",
    "The ***segments from the time series*** with benchmark data and evaluation data are then processed in the Function `mp_score()` to generate the ***matrix profiles***. For given time series, using a sliding window, sub-sequences from the time series are extracted and the distance between the extracted sub-sequence and the rest of the entire time series are calculated.\n",
    "\n",
    "- Function `sliding_window()` is called in `mp_score()` to take in a time series data and generate a 2D (w_l by n-w_l) array of sliced data using sliding window method.\n",
    "\n",
    "\n",
    "### Step 3 - Anomaly detection (peaks detection)\n",
    "\n",
    "The ***matrix profiles*** array (matrix_profile) and the time series dataframe being eveluated (evaluate_ts), limit on the number of peaks (top_peaks) into the Function `select_peak()` to generate the ***output*** with selected peaks (peaks across all channels) and the matrix profile scores of the selected peaks. \n",
    "\n",
    "- `mp_find_peaks()` is called in Function `select_peak()` with tolerance as the distance constraint for peaks to generate the array of identified peaks.\n",
    "\n",
    "- It is worth noting that the output can be varied based on the matrix profile or post-processing matrix profile approxmy, including: 1) Directly using the matrix profile; 2) Median filtering of matrix profiles; 3) Approximating the matrix profile by a peicewise linear regression.\n",
    "\n",
    "### Step 4 - Multi-channel data integration\n",
    "\n",
    "The ***output*** with selected peaks from individual channels and MPs (including peaks from each MP+channel combination) are merged and processed in Function `multi_ch_peak_detection()` and turned into arrarys of ***integrated selected peaks*** and their associated mp-score per channel.\n",
    "\n",
    "- Function `multi_ch_kde()` is called in `multi_ch_peak_detection()` to generate the selected anomlaies as an array, as well as generate the kde pdf.\n",
    "\n",
    "\n",
    "### Step 5 - Performance evaluation\n",
    "\n",
    "Users can either directly use Functions `ad_score_macro()` & `ad_score_micro()` to analyze the ***performance (recall and precision)*** of the anomaly detection ***output*** from individual channels, or from the ***integrated selected peaks***.\n",
    "\n",
    "- ad_score_macro retruns a dict of recall and precision for each channel\n",
    "- ad_score_micro returns recall and precision for each MP-channel, therefore, it is called micro. \n",
    "- The micro version also handles cases where the denominator of recall or precision is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2a9c7c-7d66-4e39-a8a5-ac8e44c5bba7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 2. Load Packages\n",
    "\n",
    "Import the following required libraries to build the environment before running the Demo project.\n",
    "\n",
    "*(There is a GPU-related pacakge that is optional for users)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e378e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0132a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Data Analysis Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array, linspace\n",
    "from random import seed, gauss\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import pwlf #The package for peicewise linear regression, users may need to install the pwlf first before import\n",
    "# pip install pwlf\n",
    "\n",
    "# Scipy-related Packages\n",
    "import scipy as sp\n",
    "from scipy import *\n",
    "from scipy.signal import *\n",
    "\n",
    "# Plot-related Packages\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import plot\n",
    "# Customize matpolib rc (runtime configuration) settings \n",
    "plt.rcParams['figure.figsize'] = 10, 5\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "\n",
    "# GPU-related Package\n",
    "# import cupy as cp\n",
    "# This package is used for faster data processing with GPU, which requires NVIDIA CUDA GPU. Users can use CPU option instead.\n",
    "# See Details in (https://docs.cupy.dev/en/stable/overview.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17930e97",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Functions Block\n",
    "\n",
    "All the functions developed for the MPAD Framework are presented in this block."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e33b4f-c926-4fbe-8dca-6eae34d68c49",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.1 Data Extraction Functions\n",
    "\n",
    "Functions used for data extraction for the units of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d7a5cd-9f87-4b63-9bf6-c61c07c688b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_extraction(benchmark_ts,evaluate_ts,MP,seg_len):\n",
    "\n",
    "    '''\n",
    "    This function process the raw time series list and extract out the list of desired segments \n",
    "    from the time series: seg_benchmark_mp,seg_evaluate_mp, \n",
    "    along with their normalized arrays: seg_benchmark_mp_scaled, seg_devaluate_mp_scaled.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    *benchmark_ts: dataframe\n",
    "        The benchmark time series dataframe read from the csv file.\n",
    "    *evaluate_ts:\n",
    "        The evaluate time series dataframe read from the csv file.\n",
    "    *MP:\n",
    "        The MilePost index number.\n",
    "    *seg_len:\n",
    "        The segmentation length index. (default is 1)\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    *seg_benchmark_mp: array\n",
    "        Segmented benchmark time series.\n",
    "    *seg_evaluate_mp: array\n",
    "        Segmented evaluate time series.\n",
    "    *seg_benchmark_mp_scaled: array\n",
    "        Normalized segmented benchmark time series.\n",
    "    *seg_evaluate_mp_scaled: array\n",
    "        Normalized segmented evaluate time series.\n",
    "    '''\n",
    "    \n",
    "    # isoltaing the data for segments (e.g., one mile post)\n",
    "    seg_benchmark_mp=benchmark_ts[(benchmark_ts[\"Full MP\"] >= MP) & (benchmark_ts[\"Full MP\"] < (MP+seg_len))]\n",
    "    seg_benchmark_mp=seg_benchmark_mp.set_index('Full MP')\n",
    "    seg_evaluate_mp=evaluate_ts[(evaluate_ts[\"Full MP\"] >= MP) &  (evaluate_ts[\"Full MP\"] < (MP+seg_len))]\n",
    "    seg_evaluate_mp=seg_evaluate_mp.set_index('Full MP')\n",
    "    \n",
    "    # copy the dataframes to be used for normlization\n",
    "    seg_benchmark_mp_scaled =seg_benchmark_mp.copy()\n",
    "    seg_evaluate_mp_scaled =seg_evaluate_mp.copy()\n",
    "    \n",
    "    # apply zero-mean normalization\n",
    "    seg_benchmark_mp_scaled =ts_normalize(seg_benchmark_mp_scaled)\n",
    "    seg_evaluate_mp_scaled =ts_normalize(seg_evaluate_mp_scaled)\n",
    "    seg_benchmark_mp_scaled=seg_benchmark_mp_scaled.to_numpy()\n",
    "    seg_evaluate_mp_scaled=seg_evaluate_mp_scaled.to_numpy()\n",
    "    \n",
    "    return seg_benchmark_mp,seg_evaluate_mp,seg_benchmark_mp_scaled,seg_evaluate_mp_scaled\n",
    "\n",
    "def ts_normalize(ts):\n",
    "\n",
    "    '''\n",
    "    This function takes in a time series dataframe ts, returns the mean-normlaized version\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    *ts: dataframe\n",
    "        The input time series dataframe.\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    *ts: dataframe\n",
    "        Mean-normalized version of the time series.\n",
    "    '''\n",
    "    \n",
    "    for column in ts.columns:\n",
    "        ts [column] = (ts[column] - ts[column].mean())\n",
    "    return ts\n",
    "\n",
    "def defect_pro(defect_list):\n",
    "    \n",
    "    '''\n",
    "    This function gets a list of defects [loc, severity, profile] \n",
    "    and returns the list of defects for different constraint.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    *defect_list: list\n",
    "        List of the defects.\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    *defect_loc: list\n",
    "        List of defects for different constraint.\n",
    "    '''\n",
    "    \n",
    "    defect_loc=[]\n",
    "    for i in defect_list:\n",
    "        defect_loc.append(i[0])\n",
    "    return defect_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea2b684-3c79-47f6-87c7-7bf8204a2271",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.2 Matrix Profile Quantification Functions\n",
    "\n",
    "Functions used to generate matrix profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7f7e32-d504-47d5-aa2b-88424bf2c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp_score(benchmark,evaluation,feature_w,gpu_flag=0):\n",
    "    \n",
    "    '''\n",
    "    This function takes the benchmark and evaluation time series and returns matrix profile.\n",
    "    There are two options of matrix profile processing: using GPU or CPU\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    *benchmark: array\n",
    "        Segmented (or normalized segemen) benchmark time series.\n",
    "    *evaluation: array\n",
    "        Segmented (or normalized segemen) evaluate time series.\n",
    "    *feature_w: int\n",
    "        Sliding window size.\n",
    "    *gpu_flag: int\n",
    "        Flag to choose use gpu or not for processing matrix profile. (default is 1)\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    *cp.asnumpy(g_mp).flatten(): array\n",
    "        Processed matrix profile.\n",
    "    *mp.flatten(): array\n",
    "        Processed matrix profile.\n",
    "    '''\n",
    "    \n",
    "    if gpu_flag:\n",
    "        # Transfering data to GPU\n",
    "        g_benchmark=cp.asarray(sliding_window(benchmark,feature_w))\n",
    "        g_evaluation=cp.asarray(sliding_window(evaluation,feature_w))\n",
    "\n",
    "        # initializing MP on GPU\n",
    "        g_mp=cp.zeros([1, g_evaluation.shape[1]], dtype = float)\n",
    "        for i in range(g_evaluation.shape[1]):\n",
    "            X=cp.tile(g_evaluation[:,[i]],g_benchmark.shape[1])\n",
    "            g_mp[0,i]=cp.min(cp.linalg.norm(cp.subtract(g_benchmark,X), ord=2, axis=0, keepdims=False))\n",
    "\n",
    "        return cp.asnumpy(g_mp).flatten()\n",
    "    else:\n",
    "        benchmark=sliding_window(benchmark,feature_w)\n",
    "        evaluation=sliding_window(evaluation,feature_w)\n",
    "        mp=np.zeros([1, evaluation.shape[1]], dtype = float)\n",
    "\n",
    "        for i in range(evaluation.shape[1]):\n",
    "            X=np.tile(evaluation[:,[i]],benchmark.shape[1])\n",
    "            mp[0,i]=np.min(np.linalg.norm(np.subtract(benchmark,X), ord=2, axis=0, keepdims=False))\n",
    "\n",
    "        return mp.flatten()\n",
    "\n",
    "def sliding_window(ts,w_l):\n",
    "    \n",
    "    '''\n",
    "    This function takes a time series (ts), and a window size (w_l), \n",
    "    and returns a 2D (w_l by n-w_l) array of sliced data using sliding window method.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    *ts: array\n",
    "        The input time series array.\n",
    "    *w_l: int\n",
    "        Sliding window size.\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    *outcome_ts: array\n",
    "        Processed sliding window time series.\n",
    "    '''\n",
    "    \n",
    "    outcome_ts = np.transpose(np.lib.stride_tricks.sliding_window_view(ts.flatten(), w_l))\n",
    "    \n",
    "    return outcome_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0dd94f-6802-440f-b98c-04acba34d555",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.3 Anomaly (Peak) Detection Functions\n",
    "\n",
    "Functions that focuses on processing matrix profile for anomaly (peak) detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcff3ca-eb70-4173-8c28-319860b3d89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp_find_peaks(mp_proxy,evaluate_ts,tolerance):\n",
    "    \n",
    "    '''\n",
    "    This function takes in a matrix profile proxy and identifies the peaks on the proxy with a predefined tolerance,\n",
    "    then outputs the identified peaks, their mp values, and mile-values. \n",
    "    \n",
    "    Matrix profile (mp) proxy is an apprxomation of the mp. For example the mp could be\n",
    "    approximated with a peicewise linear function or a median filter to reduce noise.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    *mp_proxy: array\n",
    "        Matric profile proxy array.\n",
    "    *evaluate_ts: array\n",
    "        Evaluate time series array.\n",
    "    *tolerance: int\n",
    "        The distance constraint for peaks detection.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    *peaks: array\n",
    "        Array of the selected peaks on matrix profile proxy.\n",
    "    *peak_values: array\n",
    "        Arrary of the mp_proxy function corresponding to the peaks' locations.\n",
    "    *mile_values: array\n",
    "        The peak locations in miles.\n",
    "    '''\n",
    "    \n",
    "    peaks, _ = find_peaks(mp_proxy,height=np.histogram(mp_proxy,bins=21)[1][11],distance=tolerance)\n",
    "    peak_values=mp_proxy[peaks]\n",
    "    mile_values=evaluate_ts.index.values[peaks]\n",
    "    return peaks, peak_values, mile_values\n",
    "\n",
    "def select_peak(matrix_profile,mp_ch_key,evaluate_ts,top_peaks,tolerance,reg_flag,med_filter_flag,plot_flag,defect_loc_list):\n",
    "    \n",
    "    '''\n",
    "    This function select the peaks based on the matrix profiles, and then return the selected peaks.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    *matrix_profile: array\n",
    "        Generated matrix profile.\n",
    "    *mp_ch_key: string\n",
    "        Name of the specific channel.\n",
    "    *evaluate_ts: array\n",
    "        Evaluate time series array.\n",
    "    *top_peaks: int\n",
    "        Number of top peaks selected among all the peaks that are returned from a matrix peofile or its proxy.\n",
    "    *tolerance: int\n",
    "        The minimum distance between peaks for the find_peaks function.\n",
    "    *reg_flag: int\n",
    "        Decides whether to use peicewise linear regression approximation of matrix profile.\n",
    "    *med_filter_flag:\n",
    "        Decides whether to use a median filter on matrix profile.\n",
    "    *plot_flag:\n",
    "        Decides whether to plot peaks on matrix profiles.\n",
    "    *defect_loc_list: list\n",
    "        List of ground truth defects/anomalies.\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    *output: list\n",
    "        List of results with different output combinations.\n",
    "    **selected_peaks: array\n",
    "        Array of the selected peaks.\n",
    "    **selected_peaks_mp_values: array\n",
    "        Array of matrix profile score of the selected peaks.\n",
    "    '''\n",
    "    \n",
    "    peaks, peak_values, mile_values= mp_find_peaks(matrix_profile,evaluate_ts,tolerance)\n",
    "    # mp_peak_values=matrix_profile[peaks]\n",
    "    temp=[]\n",
    "    w=10\n",
    "    mpl=len(matrix_profile)-1\n",
    "    for i in peaks:\n",
    "        f1=matrix_profile[min(i+w,mpl)]-matrix_profile[i]\n",
    "        f2=matrix_profile[i]-matrix_profile[max(0,i-w)]\n",
    "        if f1*f2<0:\n",
    "            temp.append(i)\n",
    "        \n",
    "    mp_peak_values=np.array(matrix_profile[temp])\n",
    "    mile_values=evaluate_ts.index.values[temp]\n",
    "    \n",
    "    # Here the mile values are sorted based on the matrix profile scores\n",
    "    mile_values_sorted=mile_values[np.argsort(mp_peak_values)[::-1]]\n",
    "    mp_peak_values_sorted=mp_peak_values[np.argsort(mp_peak_values)[::-1]]\n",
    "    \n",
    "    selected_peaks=mile_values_sorted[:top_peaks]\n",
    "    selected_peaks_mp_values=mp_peak_values_sorted[:top_peaks]\n",
    "    \n",
    "    # --------------- finding and processing peaks on processed matrix profile ---------------------------------\n",
    " \n",
    "    if med_filter_flag:\n",
    "        w_ma=251 # for medfilter this should be an odd integer\n",
    "        # Median filtering of matrix profiles\n",
    "        mp_smoothed=sp.signal.medfilt(matrix_profile, kernel_size=w_ma)\n",
    "        # Selecting peaks on the smoothed profile\n",
    "        peaks_smoothed,mp_peak_values_smoothed,mile_values_smoothed= mp_find_peaks(mp_smoothed,evaluate_ts,tolerance)\n",
    "    \n",
    "    if reg_flag:\n",
    "        x=evaluate_ts.index.values[:len(matrix_profile)]\n",
    "        # Approximating the matrix profile by a peicewise linear regression\n",
    "        my_pwlf = pwlf.PiecewiseLinFit(x, matrix_profile)\n",
    "        breaks = my_pwlf.fit(10) # This need to be adjusted by users.\n",
    "        mp_pwlf=my_pwlf.predict(x)\n",
    "        peaks_pwlf, mp_peak_values_pwlf,mile_values_pwlf= mp_find_peaks(mp_pwlf,evaluate_ts,tolerance)\n",
    "    \n",
    "    \n",
    "    if plot_flag:\n",
    "        font = {'family' : 'Helvetica',\n",
    "        'weight' : 'regular',\n",
    "        'size'   : 12}\n",
    "\n",
    "        plt.rcParams['figure.figsize'] = 12, 4\n",
    "        plt.rc('font', **font)\n",
    "        fig, ax = plt.subplots()\n",
    "        x=evaluate_ts.index.values[:len(matrix_profile)]; intc=0 # This is to fix the problem with issues at the begining of a mile post - change it to 2 to fix that\n",
    "        # This is plotting matrix profiles versus miles\n",
    "        plt.plot((x)[intc:len(matrix_profile)],matrix_profile[intc:len(matrix_profile)],color='k',linewidth=2,alpha=0.2, label='Matrix Profile')\n",
    "        # Plotting the top_peaks peak points\n",
    "        plt.scatter(selected_peaks,selected_peaks_mp_values,color='r',label='Top Predicted Peaks')\n",
    "        \n",
    "        if med_filter_flag:\n",
    "            plt.plot(x,mp_smoothed,label='Med. Fil. MP')\n",
    "            plt.scatter(mile_values_smoothed,mp_peak_values_smoothed,color='c',marker='^',s=100, label='Med. Fil. Peaks')\n",
    "\n",
    "        if reg_flag:\n",
    "            plt.plot(x,mp_pwlf,label='PWLF MP')\n",
    "            plt.scatter(mile_values_pwlf,mp_peak_values_pwlf,color='g',marker='H',label='PWLF Peaks')\n",
    "        \n",
    "        plt.scatter(np.array(defect_loc_list),np.random.uniform(min(matrix_profile), max(matrix_profile), size = (1,len(defect_loc_list))),color='b',marker='x',s=100,label='Ground Truth (Actual) Anomalies')\n",
    "        plt.legend()\n",
    "        plt.xlabel('Mile Post')\n",
    "        plt.ylabel('Matrix Profile Score')\n",
    "        plt.savefig('Graph_'+mp_ch_key+\".pdf\", bbox_inches='tight')\n",
    "        plt.savefig('Graph_'+mp_ch_key+\".svg\", bbox_inches='tight', format='svg')\n",
    "        plt.show()\n",
    " \n",
    "\n",
    "    # Preparing the output as a list depending on post-processing of matrix profile\n",
    "    if reg_flag and med_filter_flag:\n",
    "        output=[selected_peaks, selected_peaks_mp_values,mile_values_smoothed,mp_peak_values_smoothed,\n",
    "            mile_values_pwlf, mp_peak_values_pwlf]\n",
    "    elif med_filter_flag:\n",
    "        output=[selected_peaks, selected_peaks_mp_values,mile_values_smoothed,mp_peak_values_smoothed]\n",
    "    elif reg_flag:\n",
    "        output=[selected_peaks, selected_peaks_mp_values,mile_values_pwlf,mp_peak_values_pwlf]\n",
    "    else:\n",
    "        output=[selected_peaks, selected_peaks_mp_values]\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed147261-89b4-4eca-b7b2-d558f717db28",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.4 Multi-channel Data Integration Functions\n",
    "\n",
    "Functions that focuses on getting peaks from indiviudal channels and combines them through kernel density estimation (kde) and peak detection on kde probability distribution function (pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ce69fc-5b26-469d-bf89-8daa55296288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_ch_kde(ch_peaks,ch_peaks_scores,MP,kde_res,bw,tolerance,mode='weighted'):\n",
    "\n",
    "    '''\n",
    "    This function takes in peaks selected across m channels and use weighted/uniform mode to \n",
    "    combines them through kernel density estimation (kde) and \n",
    "    peak detection on kde probability distribution function (pdf)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    *ch_peaks: array\n",
    "        Peaks selected across m channels.\n",
    "    *ch_peaks_scores: array\n",
    "        Matrix profile score for each peak.\n",
    "    *MP:\n",
    "        Mile post index.\n",
    "    *kde_res: int\n",
    "        The kde span resolution.\n",
    "    *bw: int\n",
    "        The kde kernel bandwidth, which is used to create a probability distirbution function from the data points.\n",
    "    *tolerance: int\n",
    "        The distance constraint for peaks detection.\n",
    "    *mode: string\n",
    "        The mode for selection, weighted/uniform.\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    *selected_anomalies: array\n",
    "        Selected anomalies.\n",
    "    *mp_ticks:\n",
    "        Reference for the Mile Posts.\n",
    "    *pdf: array\n",
    "        Kde probability distribution function.\n",
    "    *peaks: array\n",
    "        Peaks identified in kde pdf.\n",
    "    '''\n",
    "    \n",
    "    ch_peaks_arr=ch_peaks.reshape(-1,1)\n",
    "\n",
    "    if mode==\"weighted\":\n",
    "        print(\"weighted KDE _________\")\n",
    "        kde=KernelDensity(kernel='gaussian',bandwidth=bw).fit(ch_peaks_arr,sample_weight=ch_peaks_scores)\n",
    "    else:\n",
    "        print(\"uniform KDE _________\")\n",
    "        kde=KernelDensity(kernel='gaussian',bandwidth=bw).fit(ch_peaks_arr)\n",
    "        \n",
    "    mp_ticks = np.linspace(MP,MP+1,num=kde_res)\n",
    "    kde_scores = kde.score_samples(mp_ticks.reshape(-1,1))\n",
    "    pdf=np.exp(kde_scores)\n",
    "    peaks, _ = find_peaks(pdf,height=np.histogram(pdf,bins=5)[1][2])\n",
    "    selected_anomalies=mp_ticks[peaks]\n",
    "    \n",
    "    return selected_anomalies,mp_ticks,pdf,peaks\n",
    "\n",
    "def multi_ch_peak_detection(peaks_dict,MP_list,attributes,kde_res,kde_bw,kde_tolerance,defect_dict,text_flag=0):\n",
    "\n",
    "    '''\n",
    "    This function takes in peak_dict (a dictionary that includes peaks data from each MP+channel combination) \n",
    "    and other variables to process them into arrays of peaks and their associated mp-score per channel.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    *peaks_dict: dictionary\n",
    "        Dictionary that includes peaks data from each MP+channel combination.\n",
    "    *MP_list: list\n",
    "        List of the Mipleposts being evaluated.\n",
    "    *attributes: list\n",
    "        Channels to be considered in the multi-channel peak detection.\n",
    "    *kde_res: int\n",
    "        The kde span resolution.\n",
    "    *kde_bw：int\n",
    "        The kde kernel bandwidth.\n",
    "    *kde_tolerance: int\n",
    "        The distance constraint for peaks detection.\n",
    "    *defect_dict：dictionary\n",
    "        Dictionary of the ground truth defects.\n",
    "    *text_flag: \n",
    "        Decides whether to print the peak selection results and ground truth defects.\n",
    "           \n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    *kde_peaks_dict: dictionary\n",
    "        Dictionary of the peaks detected through kde.\n",
    "    *pdf: array\n",
    "        kernel density estimation - probability distribution function.\n",
    "    '''\n",
    "    \n",
    "    kde_peaks_dict={}\n",
    "    \n",
    "    # Processing the peaks for kde\n",
    "    for MP in MP_list:\n",
    "        temp_peaks=np.array([])\n",
    "        temp_mp_scores=np.array([])\n",
    "        for x in attributes:\n",
    "            # extracting the peaks and their mp scores for each MP\n",
    "            temp=peaks_dict[str(MP)+'-'+str(x)]\n",
    "            temp_peaks=np.concatenate([temp_peaks,temp[0]])\n",
    "            temp_mp_scores=np.concatenate([temp_mp_scores,temp[1]])               \n",
    "        \n",
    "        selected_anomalies,mp_ticks,pdf,peaks=multi_ch_kde(temp_peaks,temp_mp_scores/max(temp_mp_scores)*100,MP,kde_res,kde_bw,kde_tolerance,mode='weighted')\n",
    "        kde_peaks_dict[str(MP)+'-multi']=[selected_anomalies]\n",
    "\n",
    "        # Prints the predicted and actual anomalies\n",
    "        if text_flag:\n",
    "            print(\"KDE Anomalies:\",np.around(selected_anomalies,3))\n",
    "            print(\"Ground Truth:\",defect_dict[MP])\n",
    "\n",
    "            \n",
    "        font = {'family' : 'Helvetica',\n",
    "        'weight' : 'regular',\n",
    "        'size'   : 12}\n",
    "\n",
    "        plt.rc('font', **font)\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_xlim(MP,MP+1)\n",
    "        ax.plot(mp_ticks, pdf/max(pdf), linewidth=3, alpha=0.9, scalex=True,label='KDE pdf | bw='+str(kde_bw))\n",
    "        for i in temp_peaks:\n",
    "            if i==temp_peaks[len(temp_peaks)-1]:\n",
    "                ax.axvline(i,ymin=0, ymax=1,c='k', alpha=0.1,label='Detected Peaks on Channels')\n",
    "            else:\n",
    "                ax.axvline(i,ymin=0, ymax=1,c='k', alpha=0.1)\n",
    "        ax.scatter(np.array(defect_pro(defect_dict[MP])), np.random.rand(len(defect_pro(defect_dict[MP]))), fc='red', alpha=1,label='Ground Truth (Actual) Anomalies')\n",
    "        ax.scatter(np.array(selected_anomalies), (pdf/max(pdf))[peaks], fc='g', alpha=1,marker='x',s=150,label='PDF Peaks')\n",
    "        #         ax.legend(loc='upper right')\n",
    "        fig.set_figwidth(8)\n",
    "        fig.set_figheight(3)\n",
    "        plt.ylabel('Density',fontsize=10)\n",
    "        plt.xlabel('Mile Post',fontsize=10)\n",
    "        plt.xticks(fontsize=10)\n",
    "        plt.yticks(fontsize=10)\n",
    "        plt.legend(prop={\"size\":10})\n",
    "        plt.savefig(\"plot_\"+str(MP)+\".pdf\",bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    return kde_peaks_dict,pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758bc079-dc14-4e66-acd8-fa82e06022a2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.5 Performance Evaluation Functions\n",
    "\n",
    "Functions that focuses on performance evaluation. \n",
    "\n",
    "Two functions are very similar: \n",
    "- `ad_score_macro` retruns a dict of recall and precision for each channel.\n",
    "- `ad_score_micro` returns recall and precision for each MP-channel, therefore, it is called micro. The micro version also handles cases where the denominator of recall or precision is zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04609524-5951-4612-8ffc-7e9249014973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ad_score_macro(peaks_dict,MP_list,attributes,inspection,threshold,top_peaks,defect_dict):\n",
    "    \n",
    "    '''\n",
    "    This function measures the performance of anomaly detection using common metrics (i.e., tp, fp, fn) \n",
    "    and retruns all the basic performance metrics in the form of a dictionary\n",
    "    and calculates and plots recall and precision for different data channels.\n",
    "    \n",
    "    It returns a dictionary of recall and precision for all mileposts for each channel, hence macro.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    *peaks_dict: dictionary\n",
    "        Dictionary of the identified peaks.\n",
    "    *MP_list: list\n",
    "        List of the Mipleposts being evaluated.\n",
    "    *attributes: list\n",
    "        Channels to be considered in evaluation.\n",
    "    *inspection: list\n",
    "        Inspections being evaluated.\n",
    "    *threshold：float\n",
    "        miles - this is the vicinity tolerance threshold to calculate the performance \n",
    "        - tolerance of distance b/w predicted and GT anomalies.\n",
    "    *top_peaks：int\n",
    "        The number of top peaks selected among all the peaks that are returned from a matrix peofile or its proxy.\n",
    "    *defect_dict：dictionary\n",
    "        Ground truth defects dictionary.\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    *scores_dict: dictionary\n",
    "        Dictionary of the performance evaluation results.\n",
    "    '''\n",
    "    \n",
    "    scores_dict={} # Initailizing the dictionary for evaluation metrics\n",
    "    \n",
    "    for x in attributes:\n",
    "        tp=0;tp_2=0;fn=0;fp=0 # Initalizing basic metrics\n",
    "        \n",
    "        for MP in MP_list:\n",
    "            gt_count=len(defect_dict[MP]) # Getting the total number of grougd truth anomalies\n",
    "            temp=str(MP)+'-'+str(x)\n",
    "\n",
    "            for j in defect_pro(defect_dict[MP]):\n",
    "                dis=np.absolute(np.array(peaks_dict[temp][0])-j) # Calculating the distance between predicted and actual anomalies\n",
    "                if dis.size>0 and min(dis)<threshold:\n",
    "                    tp+=1\n",
    "                else:\n",
    "                    fn+=1\n",
    "                    \n",
    "            if gt_count==0:\n",
    "                    fp+=len(peaks_dict[temp][0]) # all detected peaks will be false positives\n",
    "            else:\n",
    "                for k in peaks_dict[temp][0]:\n",
    "                    dis=np.absolute(np.array(defect_pro(defect_dict[MP]))-k)\n",
    "\n",
    "                    if dis.size>0 and min(dis)>threshold:\n",
    "                        fp+=1\n",
    "                    if dis.size>0 and min(dis)<threshold:\n",
    "                        tp_2+=1\n",
    "\n",
    "        #print(x,tp,fn,fp) #Uncomments to see the values for each channel   \n",
    "\n",
    "        mp_metrics=np.array([round(tp/(tp+fn),2),round(tp/(tp+fp),2)])\n",
    "        scores_dict[x]=mp_metrics\n",
    "\n",
    "    #------- Output Block ---------\n",
    "    print('--------------------------------------------------------------------------------------------------')\n",
    "    print('The >>',inspection.upper(),'<< inspection')\n",
    "    print('Detection tolerance:>>',threshold,'<< miles')\n",
    "    print('Selecting the top >>',top_peaks,'<< peaks')\n",
    "    print()\n",
    "    # print('Atrribute','tp','fn','fp')      \n",
    "    scores_df=pd.DataFrame.from_dict(scores_dict)\n",
    "    scores_df=scores_df.rename(index={0: 'Recall',1: 'Precision'})\n",
    "    scores_df\n",
    "    scores_df.T.plot.bar()\n",
    "#     scores_df.T.plot.scatter(x='Recall', y='Precision', s=50)\n",
    "#     for idx, row in scores_df.T.iterrows(): \n",
    "#         plt.text(row['Recall']+gauss(0, 0.05), row['Precision']+gauss(0, 0.03), idx,fontsize=10)\n",
    "    plt.show()\n",
    "    return scores_dict\n",
    "\n",
    "def ad_score_micro(peaks_dict,MP_list,attributes,threshold,defect_dict):\n",
    "    \n",
    "    '''\n",
    "    This function measures the performance of anomaly detection using common metrics (i.e., tp, fp, fn) \n",
    "    and retruns all the basic performance metrics in the form of a dictionary\n",
    "    and calculates and plots recall and precision for different data channels.\n",
    "    \n",
    "    It returns a dictionary of recall and precision for all mileposts-channel keys, hence micro.\n",
    "    Micro handles the cases where denominator of recall and/or precion is zero.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    *peaks_dict: dictionary\n",
    "        Dictionary of the identified peaks.\n",
    "    *MP_list: list\n",
    "        List of the Mipleposts being evaluated.\n",
    "    *attributes: list\n",
    "        Channels to be considered in evaluation.\n",
    "    *threshold: float\n",
    "        miles - this is the vicinity tolerance threshold to calculate the performance \n",
    "        - tolerance of distance b/w predicted and GT anomalies.\n",
    "    *defect_dict：dictionary\n",
    "        Ground truth defects dictionary.\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    *scores_dict: dictionary\n",
    "        Dictionary of the performance evaluation results.\n",
    "    '''\n",
    "    \n",
    "    scores_dict={}\n",
    "\n",
    "    for MP in MP_list:\n",
    "        gt_count=len(defect_dict[MP])\n",
    "        \n",
    "        for x in attributes:\n",
    "            temp=str(MP)+'-'+str(x)\n",
    "            tp=0;tp_2=0;fp=0;fn=0\n",
    "\n",
    "            for j in defect_pro(defect_dict[MP]): #[0],<<<<=======================\n",
    "                dis=np.absolute(np.array(peaks_dict[temp][0])-j)\n",
    "\n",
    "                if dis.size>0 and min(dis)<threshold:\n",
    "                    tp+=1\n",
    "                else:\n",
    "                    fn+=1\n",
    "            \n",
    "            if gt_count==0:\n",
    "                fp+=len(peaks_dict[temp][0]) # all detected peaks will be false positives\n",
    "                \n",
    "            for k in peaks_dict[temp][0]:\n",
    "                dis=np.absolute(np.array(defect_pro(defect_dict[MP]))-k)\n",
    "                if dis.size>0 and min(dis)>threshold:\n",
    "                    fp+=1\n",
    "                if dis.size>0 and min(dis)<threshold:\n",
    "                    tp_2+=1 #Have not used this in showing the outcome\n",
    "\n",
    "            if tp+fp!=0 and tp+fn!=0:\n",
    "                scores_dict[temp]=[len(peaks_dict[temp][0]),gt_count,tp,fp,fn,round(tp/(tp+fn),2),round(tp/(tp+fp),2)]\n",
    "            elif tp+fp==0:\n",
    "                scores_dict[temp]=[len(peaks_dict[temp][0]),gt_count,tp,fp,fn,round(tp/(tp+fn),2),'na']\n",
    "            elif tp+fn==0:\n",
    "                scores_dict[temp]=[len(peaks_dict[temp][0]),gt_count,tp,fp,fn,'na',round(tp/(tp+fp),2)]\n",
    "            else:\n",
    "                scores_dict[temp]=[len(peaks_dict[temp][0]),gt_count,tp,fp,fn,'na',round(tp/(tp+fp),2)]\n",
    "    scores_dict\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0e48b7-1f23-470a-b176-b50803e785b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.6 Experiments Functions\n",
    "\n",
    "Function that process the calculated performance of different data channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7a0f40-c891-4cc0-b167-36073fb0a5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_performing_channels(geo_flag,inspection,vicinity_threshold,top_peaks,scores_dict,top_rows):\n",
    "    \n",
    "    '''\n",
    "    This function focuses on processing the performance of different data channels.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    *geo_flag: int\n",
    "        Decides to use acceleration versus geometry channels.\n",
    "    *inspection: list\n",
    "        Inspections being evaluated.\n",
    "    *attributes: list\n",
    "        Channels to be considered in evaluation.\n",
    "    *vicinity_threshold: float\n",
    "        Vicinity tolerance threshold to calculate the performance.\n",
    "    *top_peaks：int\n",
    "        The number of top peaks selected among all the peaks.\n",
    "    *scores_dict：dictionary\n",
    "        Dictionary of the performance evaluation results.\n",
    "    *top_rows：int\n",
    "        Number of top rows to be selected and show.\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    *scores_df.head(top_rows): dictionary\n",
    "        Dictionary of the sorted performance evaluation results with selected top rows.\n",
    "    '''\n",
    "    \n",
    "    if geo_flag:\n",
    "        print(\"Evaluating -- GEOMETRY -- channel for the >>\",inspection,\"<< inspection\")\n",
    "    else:\n",
    "        print(\"Evaluating -- Acceleration -- channel for the >>\",inspection,\"<< inspection\")\n",
    "    print(\"Performance threshold:\",vicinity_threshold,\"  miles\")\n",
    "    print('Selecting the >>',top_peaks,'<< peaks')\n",
    "    print(\"\")\n",
    "\n",
    "    scores_df=pd.DataFrame.from_dict(scores_dict)\n",
    "    scores_df=scores_df.T.sort_values(by=[0], ascending=False).rename(columns={0: 'Recall',1: 'Precision'})\n",
    "    scores_df\n",
    "    \n",
    "    return scores_df.head(top_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673e944d-60f7-45d8-90ab-2764bed11f89",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Demo Project\n",
    "\n",
    "This is the demo of the MPAD with an anomaly detection task and some sample datasets. In this task, we are detecting anomalies on a railroad time series data, in which the time series data are acceleration and geometry sensor readings across a part of railroad. In this demo project we show the two geometry sensor reading as channels: *Right Profile 62, Left Profile*.\n",
    "\n",
    "\n",
    "***Note that sample data are not provided, and the data below are dummy examples for this Demo Project, and can't directly run and generate outputs.***\n",
    "\n",
    "***Users can customize their own time series datasets and adjust the parameters according to their needs.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50795e9",
   "metadata": {},
   "source": [
    "## 4.1 Groud Truth Anomalies Data\n",
    "\n",
    "Ground truth data - specific to data sets \n",
    "\n",
    "The data should be adjusted for each project - The format of the ground truth dictionary is as presnted below.\n",
    "\n",
    "Similar dictionaries should be populated (either manual or through code) for a datset that is evaluated through this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b702d6a5-9157-46f9-beaf-661ece636ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for ppopulating the ground truth data assuming two inspections with two miles posts 1 and 2\n",
    "# The right side is a dictionary key input | left side a list of lists. Each one of the lists include ground truth anomlay location, level, and channel\n",
    "\n",
    "# First Inspection\n",
    "defect_dict_1={}\n",
    "defect_dict_1[1]=[[1.15,3,'Left Prof'],[1.65,2,'Right Profile 62']]\n",
    "defect_dict_1[2]=[[1.62,1,'Right Profile']]\n",
    "\n",
    "# Second Inspection\n",
    "defect_dict_2={}\n",
    "defect_dict_2[1]=[[1.63,2,'Left Prof']]\n",
    "defect_dict_2[2]=[] # representing no defect on this milepost.\n",
    "\n",
    "defect_dict_list=[defect_dict_1,defect_dict_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb73fa0",
   "metadata": {},
   "source": [
    "## 4.2 Project Parameters\n",
    "\n",
    "Users need to customize their project parameters on their specific tasks and datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6095062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------Project Specific Data---------------------------------#\n",
    "\n",
    "# Data Channels\n",
    "accelerations=['Your proper channel names']\n",
    "geometry=['Right Prof 62','Left Profile'] # Example shown for this demo project\n",
    "\n",
    "# Mipleposts being evaluated\n",
    "MP_list=[1] # Example shown for this demo project\n",
    "\n",
    "# Inspections being evaluated \n",
    "inspections=['first','second'] # Example shown for this demo project\n",
    "ins_inx=1\n",
    "\n",
    "# Selecting the defect dictionary for plotting\n",
    "defect_dict=defect_dict_list[ins_inx]\n",
    "\n",
    "#---------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "#--------------Parameters----------------------------------------------#\n",
    "\n",
    "##-------------Commonly Changed Parameters----------------------------##\n",
    "gpu_flag=0    # Using GPU for matrix profile calculation - default is 0\n",
    "geo_flag=1    # changing b/w geometry and acceleration channels\n",
    "top_peaks=3   # peak selection and processing parameters\n",
    "\n",
    "# Evaluation Parameter\n",
    "vicinity_threshold=0.03\n",
    "\n",
    "# Change attribute as per implementation\n",
    "if geo_flag:\n",
    "    attributes=geometry\n",
    "else:\n",
    "    attributes=accelerations[0:1]\n",
    "##--------------------------------------------------------------------##\n",
    "\n",
    "on_off_falg=1 # This is the flag that turns matrix profile calculations on or off\n",
    "feature_w=75  # sliding window size\n",
    "ma_flag=0     # parameters to apply a median filter to matrix profile to reduce noise\n",
    "bw=0.01       # The kernel bandwidth\n",
    "\n",
    "reg_flag=0          # Decides whether to use peicewise linear regression approximation of matrix profile\n",
    "med_filter_flag=1   # Decides whether to use a median filter on matrix profile\n",
    "plot_flag=1         # Decides whether to plot peaks on matrix profiles\n",
    "\n",
    "kde_res=1000        # The kde span resolution\n",
    "kde_bw=0.02         # The kde bandwidth is used to create a probability distirbution function from the data points\n",
    "ps_tolerance=120    # The minimum distance between peaks for the find_peaks function\n",
    "kde_tolerance=kde_res/20 # The distance constraint for peaks detection\n",
    "    \n",
    "matrix_profile_dict={} # In case of storing the matrix profile dictionary; not used in this demo project\n",
    "\n",
    "#----------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fa14fd",
   "metadata": {},
   "source": [
    "## 4.3 Import Dataset\n",
    "\n",
    "Users need to change this into their customized time series datasets as benchmark and evaluation time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40dd0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the data from the files for becnhmark and evaluation inspections---\n",
    "if attributes==geometry:\n",
    "    benchmark_ts= pd.read_csv('Your Benchmark Geometry Time Series File.csv')\n",
    "    evaluation_ts=pd.read_csv('Your Evaluation Geometry Time Series File.csv')  \n",
    "else:\n",
    "    benchmark_ts= pd.read_csv('Your Benchmark Acceleration Time Series File.csv')\n",
    "    evaluation_ts= pd.read_csv('Your Benchmark Acceleration Time Series File.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43be3246",
   "metadata": {},
   "source": [
    "## 4.4 Matrix Profiling & Anomaly Detection\n",
    "\n",
    "The main class of this demo project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa3b27-ee0c-4160-ab9c-317e04825eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the dictionary to store peaks and their associated matrix profile scores and locations in miles\n",
    "ch_peaks_dict={}\n",
    "\n",
    "# Going through list of mileposts being evaluated, form matrix-profiles, and detect all peaks/anomalies for each channel\n",
    "for MP in MP_list:\n",
    "    for x in attributes:\n",
    "        benchmark_ts_x=benchmark_ts[['Location of Your time series',x]]\n",
    "        evaluation_ts_x=evaluation_ts[['Location of Your time series',x]]\n",
    "\n",
    "        benchmark_ts_mp,evaluation_ts_mp,benchmark_ts_mp_scaled,evaluation_ts_mp_scaled=dataset_extraction(benchmark_ts_x,evaluation_ts_x,MP,1)\n",
    "\n",
    "        # The main matrix profile computation ----------------------------------------------------\n",
    "        if on_off_falg:\n",
    "            matrix_profile=mp_score(benchmark_ts_mp_scaled,evaluation_ts_mp_scaled,feature_w,gpu_flag=0)\n",
    "        else:\n",
    "            matrix_profile# Implement the code to load calculated matrix profiles\n",
    "        #--------------------------------Single Channel Peak Detection -------------------------------\n",
    "        key=str(MP)+'-'+str(x)\n",
    "        # Once you generate the image delete key2 line and replace key2 with key in print\n",
    "        key2=str(MP)+'-'+str(x) \n",
    "        print(key2)\n",
    "        output=select_peak(matrix_profile,key,evaluation_ts_mp,top_peaks,ps_tolerance,reg_flag,med_filter_flag,plot_flag,defect_pro(defect_dict[MP]))\n",
    "        ch_peaks_dict[key]=output # Storing the data for multi channel assessments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eccc0b",
   "metadata": {},
   "source": [
    "**Example Outputs:**\n",
    "\n",
    "--------------------------------------------------------------------------------------------------\n",
    "\n",
    "1-Right Prof 62\n",
    "<img src=\"imgs/RightProf_peaks.png\" width=\"1200\"/>\n",
    "\n",
    "1-Left Profile\n",
    "<img src=\"imgs/LeftProf_peaks.png\" width=\"1200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c0e51f",
   "metadata": {},
   "source": [
    "## 4.5 Performance Evaluation\n",
    "\n",
    "Evaluating the performance of individual channels in detecting the anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e2b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dict=ad_score_macro(ch_peaks_dict,MP_list,attributes,inspections[ins_inx],vicinity_threshold,top_peaks,defect_dict_list[ins_inx])\n",
    "\n",
    "print('==================================================================================================')\n",
    "print('\\033[1m' +'Dictionary of Performance Metrics for Channels' + '\\033[0m')\n",
    "pd.DataFrame.from_dict(scores_dict).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7a5b68",
   "metadata": {},
   "source": [
    "**Example Outputs:**\n",
    "\n",
    "--------------------------------------------------------------------------------------------------\n",
    "\n",
    "The >> SECOND << inspection\n",
    "\n",
    "Detection tolerance:>> 0.03 << miles\n",
    "\n",
    "Selecting the top >> 3 << peaks\n",
    "\n",
    "<img src=\"imgs/individual_cha_perf.png\" width=\"1200\"/>\n",
    "\n",
    "==================================================================================================\n",
    "\n",
    "**Dictionary of Performance Metrics for Channels**\n",
    "\n",
    "|  | Recall | Precision |\n",
    "| --- | --- | --- |\n",
    "| Right Prof 62 | 1.0 | 1.0 |\n",
    "| Left Profile | 1.0 | 0.5 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6922d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting channels based on their recall value\n",
    "print('\\033[1m' +'Sorted based on channel recall' + '\\033[0m')\n",
    "top_rows=len(geometry)\n",
    "top_per_ch=top_performing_channels(geo_flag,inspections[ins_inx],vicinity_threshold,top_peaks,scores_dict,top_rows)\n",
    "top_per_ch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259574ff",
   "metadata": {},
   "source": [
    "**Example Outputs:**\n",
    "\n",
    "--------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "**Sorted based on channel recall**\n",
    "\n",
    "Evaluating -- GEOMETRY -- channel for the >> second << inspection\n",
    "\n",
    "Performance threshold: 0.03   miles\n",
    "\n",
    "Selecting the >> 3 << peaks\n",
    "\n",
    "|  | Recall | Precision |\n",
    "| --- | --- | --- |\n",
    "| Right Prof 62 | 1.0 | 1.0 |\n",
    "| Left Profile | 1.0 | 0.5 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba4cb56",
   "metadata": {},
   "source": [
    "## 4.6 Multi-Channel Data Integration\n",
    "\n",
    "Ensembling all peaks/anomalies into a kde pdf and detect probabilistic anomalies on the pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d2a6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\033[1m' + 'Ensemble Analysis Using Kernel Density Estimation' + '\\033[0m')\n",
    "multi_ch_peaks_dict,pdf=multi_ch_peak_detection(ch_peaks_dict,MP_list,attributes,kde_res,kde_bw,kde_tolerance,defect_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13532cf1",
   "metadata": {},
   "source": [
    "**Example Outputs:**\n",
    "\n",
    "--------------------------------------------------------------------------------------------------\n",
    "\n",
    "**Ensemble Analysis Using Kernel Density Estimation**\n",
    "\n",
    "weighted KDE _________\n",
    "\n",
    "<img src=\"imgs/weighted_kde.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5390e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the performance of multiple channels in detecting all exceptions\n",
    "scores_dict_kde=ad_score_macro(multi_ch_peaks_dict,MP_list,['multi'],inspections[ins_inx],vicinity_threshold,top_peaks,defect_dict_list[ins_inx])\n",
    "\n",
    "print('==================================================================================================')\n",
    "print('\\033[1m' +'Dictionary of Aggregated Performance Metrics' + '\\033[0m')\n",
    "print(pd.DataFrame.from_dict(scores_dict_kde).T.rename(columns={0: 'Recall',1: 'Precision'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9be9ff",
   "metadata": {},
   "source": [
    "**Example Outputs:**\n",
    "\n",
    "--------------------------------------------------------------------------------------------------\n",
    "\n",
    "The >> SECOND << inspection\n",
    "\n",
    "Detection tolerance:>> 0.03 << miles\n",
    "\n",
    "Selecting the top >> 3 << peaks\n",
    "\n",
    "<img src=\"imgs/multi_cha_perf.png\" width=\"800\"/>\n",
    "\n",
    "==================================================================================================\n",
    "\n",
    "**Dictionary of Aggregated Performance Metrics**\n",
    "\n",
    "|  | Recall | Precision |\n",
    "| --- | --- | --- |\n",
    "| multi | 1.0 | 1.0 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
